"""
Test the improved repo analysis
"""
import asyncio
from tools import analyze_specific_repo_enhanced

async def test_improvements():
    print("ğŸ§ª Testing improved repo analysis...")
    
    try:
        result = await analyze_specific_repo_enhanced('Lightly-GPT')
        
        if 'error' in result:
            print(f"âŒ Error: {result['error']}")
            return
        
        print("âœ… Analysis completed!")
        print(f"ğŸ“ Repo: {result['basic_info']['name']}")
        
        # Quality metrics
        quality = result['quality_metrics']
        print(f"\nğŸ” Quality Metrics:")
        print(f"  â€¢ Tests: {'âœ…' if quality['has_tests'] else 'âŒ'}")
        print(f"  â€¢ CI/CD: {'âœ…' if quality['has_ci'] else 'âŒ'}")
        print(f"  â€¢ License: {'âœ…' if quality['has_license'] else 'âŒ'}")
        print(f"  â€¢ Quality Score: {quality['quality_score']}/100")
        
        # README analysis
        readme = result['readme']
        print(f"\nğŸ“š README Analysis:")
        print(f"  â€¢ Length: {readme['readme_length']} characters")
        print(f"  â€¢ Quality: {readme['readme_quality']}")
        print(f"  â€¢ Has Installation: {'âœ…' if readme['has_installation'] else 'âŒ'}")
        print(f"  â€¢ Has Usage: {'âœ…' if readme['has_usage'] else 'âŒ'}")
        print(f"  â€¢ Sections: {readme['sections_found']}")
        
        # Overall
        print(f"\nâ­ Overall Score: {result['overall_score']}/100")
        
    except Exception as e:
        print(f"âŒ Error: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    asyncio.run(test_improvements())
